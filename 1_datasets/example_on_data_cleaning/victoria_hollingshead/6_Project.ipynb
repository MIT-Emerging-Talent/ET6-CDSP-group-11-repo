{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Fundamentals: Project\n",
    "\n",
    "* * * \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Apply the skills you have learned in this workshop series to a health dataset.\n",
    "* Understand how to navigate file structures in Jupyter.\n",
    "* Apply Pandas methods to concatenate dataframes, clean up data, count and group values, and visualize correlations. \n",
    "* Use your search engine to look up how functions and methods work.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üìù **Poll:** A Zoom poll to help you learn!\n",
    "\n",
    "\n",
    "### Sections\n",
    "1. [üöÄ Project](#project)\n",
    "2. [Step 1: Import the Data](#data)\n",
    "3. [Step 2: Data Cleaning](#clean)\n",
    "4. [Step 3: Data Analysis](#eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project'></a>\n",
    "\n",
    "# üöÄ Project\n",
    "\n",
    "### Data: California Health Interview Survey\n",
    "The [California Health Interview Survey (CHIS)](https://healthpolicy.ucla.edu/chis/Pages/default.aspx) is the nation's largest state health survey and a critical source of data on Californians as well as on the state's various racial and ethnic groups. The data has been altered for demonstration purposes.\n",
    "\n",
    "The data has the following columns:\n",
    "\n",
    "- `general_health`: Self-Reported assessment of general health\n",
    "- `veg_perweek`: How many vegetables consumed per week\n",
    "- `feel_left_out`: How often feeling left out\n",
    "- `poverty_level`: Poverty level as Times of 100% Federal Poverty Line (FPL)\n",
    "- `household_tenure`: Self-Reported household tenure\n",
    "- `interview_language`: Language of interview\n",
    "\n",
    "For this project, the goal we want to accomplish is **visualizing the relationship between poverty level and general health**. We will bring together basic programming and data science techniques you have learned to do this.\n",
    "\n",
    "üîî **Question**: Are there other research questions you could imagine asking with this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='data'></a>\n",
    "\n",
    "# Step 1: Importing Data \n",
    "\n",
    "Before we import our data, a few words on **filepaths**. \n",
    "\n",
    "A filepath is the location of a file on your system. There are two kinds of filepaths:\n",
    "\n",
    "* **absolute**: The filepath from the top level folder of your system.\n",
    "* **relative**: The filepath relative to the current working directory (i.e. this notebook's location). \n",
    "\n",
    "<img src=\"../img/filetree.png\" alt=\"Absolute and relative filepaths\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `listdir()`\n",
    "\n",
    "When you are figuring out what filepath to use, you can use `os.listdir([PATH])` to list all subdirectories in a path. For example, let's see what directories are available to us in the current folder (noted with a dot `.`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6_Project.ipynb', 'chis_data', 'README.md']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up the items in the folder after moving up one level works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['victoria_hollingshead',\n",
       " 'LICENSE',\n",
       " 'anjali_n_ravunniarath',\n",
       " 'ameya_naik',\n",
       " '.gitignore',\n",
       " 'README.md',\n",
       " '.ls-lint.yml',\n",
       " '.git',\n",
       " '.assets',\n",
       " '.vscode']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** In Jupyter Lab's File Browser (the folder icon in top left of your screen),  you can navigate to a folder, right-click on a file and select `Copy Path` to get the absolute filepath of a file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Locating the Data\n",
    "\n",
    "Try to locate the files in the \"chis_data\" folder, which is in the \"data\" folder, which is in the main \"Python-Intermediate\" folder. Using `pd.read_csv()`, read in all three data frames and assign them to the three variables defined below.\n",
    "\n",
    "üí° **Tip**: You can use Jupyter Lab's File Browser to the left of your screen to get a sense of where the \"chis_data\" folder is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df_eng = pd.read_csv(\"chis_data/chis_eng.csv\", sep=\",\")\n",
    "df_esp = pd.read_csv(\"chis_data/chis_esp.csv\", sep=\",\")\n",
    "df_other = pd.read_csv(\"chis_data/chis_other.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenating DataFrames\n",
    "\n",
    "Look up the [documentation for Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/general_functions.html), and see if you can find a function that **concatenates** the three DataFrames we have now. Save the concatenated list in a new variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.concat([df_eng,df_esp, df_other])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Let's take a look at the final data frame.\n",
    "\n",
    "1. How many rows and columns are there in the concatenated DataFrame?\n",
    "2. How many numeric columns are there in the dataset?\n",
    "3. What data type are the values in the `poverty_level` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>general_health</th>\n",
       "      <th>veg_perweek</th>\n",
       "      <th>feel_left_out</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>household_tenure</th>\n",
       "      <th>interview_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>2</td>\n",
       "      <td>SOME OF THE TIME</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>4</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAIR</td>\n",
       "      <td>11</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>0-99% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>200-299% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>2</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200-299% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>11</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FAIR</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>200-299% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   general_health  veg_perweek     feel_left_out       poverty_level  \\\n",
       "0             NaN            0               NaN  300% FPL AND ABOVE   \n",
       "1       VERY GOOD            2  SOME OF THE TIME  300% FPL AND ABOVE   \n",
       "2       VERY GOOD           20               NaN        100-199% FPL   \n",
       "3            GOOD            4       HARDLY EVER        100-199% FPL   \n",
       "4            GOOD            6               NaN  300% FPL AND ABOVE   \n",
       "5            FAIR           11       HARDLY EVER  300% FPL AND ABOVE   \n",
       "6             NaN            9       HARDLY EVER           0-99% FPL   \n",
       "7            GOOD            0       HARDLY EVER        200-299% FPL   \n",
       "8            GOOD            8               NaN        100-199% FPL   \n",
       "9             NaN           18       HARDLY EVER  300% FPL AND ABOVE   \n",
       "10      VERY GOOD           22               NaN        100-199% FPL   \n",
       "11      VERY GOOD            2       HARDLY EVER  300% FPL AND ABOVE   \n",
       "12      VERY GOOD            3               NaN  300% FPL AND ABOVE   \n",
       "13            NaN           12               NaN        200-299% FPL   \n",
       "14      VERY GOOD           10               NaN  300% FPL AND ABOVE   \n",
       "15           GOOD           11       HARDLY EVER  300% FPL AND ABOVE   \n",
       "16            NaN            2               NaN  300% FPL AND ABOVE   \n",
       "17           FAIR            2               NaN        100-199% FPL   \n",
       "18      VERY GOOD            1       HARDLY EVER        200-299% FPL   \n",
       "19           GOOD            2               NaN  300% FPL AND ABOVE   \n",
       "\n",
       "               household_tenure interview_language  \n",
       "0   RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "1                           OWN            ENGLISH  \n",
       "2   RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "3                           OWN            ENGLISH  \n",
       "4   RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "5                           OWN            ENGLISH  \n",
       "6   RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "7                           OWN            ENGLISH  \n",
       "8                           OWN            ENGLISH  \n",
       "9                           OWN            ENGLISH  \n",
       "10                          OWN            ENGLISH  \n",
       "11                          OWN            ENGLISH  \n",
       "12  RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "13  RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "14                          OWN            ENGLISH  \n",
       "15                          OWN            ENGLISH  \n",
       "16  RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "17  RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "18                          OWN            ENGLISH  \n",
       "19                          OWN            ENGLISH  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df.head(20) #Makes you see all csv file concated, you can see the first couple lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22160, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #check the size of data set, returns rows and columns\n",
    "#Shape is an attribute not a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['general_health', 'veg_perweek', 'feel_left_out', 'poverty_level',\n",
       "       'household_tenure', 'interview_language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: general_health\n",
      "Unique values: [nan 'VERY GOOD' 'GOOD' 'FAIR' 'POOR']\n",
      "Value counts:  general_health\n",
      "VERY GOOD    8065\n",
      "GOOD         6270\n",
      "NaN          4898\n",
      "FAIR         2324\n",
      "POOR          603\n",
      "Name: count, dtype: int64\n",
      "columns: veg_perweek\n",
      "Unique values: [ 0  2 20  4  6 11  9  8 18 22  3 12 10  1 16  5  7 17 13 19 14 23 21 15\n",
      " 24 26 25 27 28 29]\n",
      "Value counts:  veg_perweek\n",
      "0     2185\n",
      "3     2174\n",
      "4     2133\n",
      "2     1986\n",
      "5     1891\n",
      "1     1650\n",
      "6     1549\n",
      "7     1201\n",
      "16    1187\n",
      "8      870\n",
      "11     860\n",
      "9      851\n",
      "10     811\n",
      "12     681\n",
      "13     462\n",
      "14     380\n",
      "15     301\n",
      "17     283\n",
      "18     217\n",
      "19     120\n",
      "20      91\n",
      "21      84\n",
      "23      64\n",
      "22      57\n",
      "24      35\n",
      "25      21\n",
      "26       9\n",
      "27       5\n",
      "28       1\n",
      "29       1\n",
      "Name: count, dtype: int64\n",
      "columns: feel_left_out\n",
      "Unique values: [nan 'SOME OF THE TIME' 'HARDLY EVER' 'OFTEN']\n",
      "Value counts:  feel_left_out\n",
      "NaN                 13713\n",
      "HARDLY EVER          6612\n",
      "SOME OF THE TIME     1576\n",
      "OFTEN                 259\n",
      "Name: count, dtype: int64\n",
      "columns: poverty_level\n",
      "Unique values: ['300% FPL AND ABOVE' '100-199% FPL' '0-99% FPL' '200-299% FPL']\n",
      "Value counts:  poverty_level\n",
      "300% FPL AND ABOVE    14612\n",
      "100-199% FPL           2823\n",
      "200-299% FPL           2800\n",
      "0-99% FPL              1925\n",
      "Name: count, dtype: int64\n",
      "columns: household_tenure\n",
      "Unique values: ['RENT/SOME OTHER ARRANGEMENT' 'OWN']\n",
      "Value counts:  household_tenure\n",
      "OWN                            15473\n",
      "RENT/SOME OTHER ARRANGEMENT     6687\n",
      "Name: count, dtype: int64\n",
      "columns: interview_language\n",
      "Unique values: ['ENGLISH' 'SPANISH' 'OTHER LANGUAGE']\n",
      "Value counts:  interview_language\n",
      "ENGLISH           21131\n",
      "SPANISH             656\n",
      "OTHER LANGUAGE      373\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Find unique columns in the dataset\n",
    "columns = df.columns\n",
    "for col in columns:\n",
    "    unique_col = df[col].unique()\n",
    "    print('columns:', col)\n",
    "    print(\"Unique values:\", unique_col)\n",
    "    print(\"Value counts: \", df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good research question is what you do with your non values (NaN), based on the SITUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veg_perweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.413538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.292092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        veg_perweek\n",
       "count  22160.000000\n",
       "mean       6.413538\n",
       "std        5.292092\n",
       "min        0.000000\n",
       "25%        2.000000\n",
       "50%        5.000000\n",
       "75%       10.000000\n",
       "max       29.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22160 entries, 0 to 372\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   general_health      17262 non-null  object\n",
      " 1   veg_perweek         22160 non-null  int64 \n",
      " 2   feel_left_out       8447 non-null   object\n",
      " 3   poverty_level       22160 non-null  object\n",
      " 4   household_tenure    22160 non-null  object\n",
      " 5   interview_language  22160 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Another layer of information to tell us about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>general_health</th>\n",
       "      <th>veg_perweek</th>\n",
       "      <th>feel_left_out</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>household_tenure</th>\n",
       "      <th>interview_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>2</td>\n",
       "      <td>SOME OF THE TIME</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>4</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>4</td>\n",
       "      <td>OFTEN</td>\n",
       "      <td>200-299% FPL</td>\n",
       "      <td>OWN</td>\n",
       "      <td>OTHER LANGUAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300% FPL AND ABOVE</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>OTHER LANGUAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200-299% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>OTHER LANGUAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>7</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>OTHER LANGUAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>VERY GOOD</td>\n",
       "      <td>5</td>\n",
       "      <td>HARDLY EVER</td>\n",
       "      <td>100-199% FPL</td>\n",
       "      <td>RENT/SOME OTHER ARRANGEMENT</td>\n",
       "      <td>OTHER LANGUAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22160 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    general_health  veg_perweek     feel_left_out       poverty_level  \\\n",
       "0              NaN            0               NaN  300% FPL AND ABOVE   \n",
       "1        VERY GOOD            2  SOME OF THE TIME  300% FPL AND ABOVE   \n",
       "2        VERY GOOD           20               NaN        100-199% FPL   \n",
       "3             GOOD            4       HARDLY EVER        100-199% FPL   \n",
       "4             GOOD            6               NaN  300% FPL AND ABOVE   \n",
       "..             ...          ...               ...                 ...   \n",
       "368           GOOD            4             OFTEN        200-299% FPL   \n",
       "369           GOOD            2               NaN  300% FPL AND ABOVE   \n",
       "370           GOOD           10               NaN        200-299% FPL   \n",
       "371           GOOD            7       HARDLY EVER        100-199% FPL   \n",
       "372      VERY GOOD            5       HARDLY EVER        100-199% FPL   \n",
       "\n",
       "                household_tenure interview_language  \n",
       "0    RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "1                            OWN            ENGLISH  \n",
       "2    RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "3                            OWN            ENGLISH  \n",
       "4    RENT/SOME OTHER ARRANGEMENT            ENGLISH  \n",
       "..                           ...                ...  \n",
       "368                          OWN     OTHER LANGUAGE  \n",
       "369  RENT/SOME OTHER ARRANGEMENT     OTHER LANGUAGE  \n",
       "370  RENT/SOME OTHER ARRANGEMENT     OTHER LANGUAGE  \n",
       "371  RENT/SOME OTHER ARRANGEMENT     OTHER LANGUAGE  \n",
       "372  RENT/SOME OTHER ARRANGEMENT     OTHER LANGUAGE  \n",
       "\n",
       "[22160 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's reset the index\n",
    "df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "\n",
    "# Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we will want to remove some missing values in a DataFrame. Have a look at the `general_health` column and find the missing values using the `.isna()` method. Then, use `.sum()` to sum the amount of undefined (NaN) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4898)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "total_nan_general = df['general_health'].isna().sum()\n",
    "total_nan_general\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4898)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"general_health\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the non-existent values in this column with the `.dropna()` method. Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) to see how to do this.\n",
    "\n",
    "üí° **Tip**: Use the `subset` argument to select a specific column to remove values from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "no_nan_df = df.dropna(subset=['general_health'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_nan_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m no_nan_df = \u001b[43mno_nan_df\u001b[49m.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mfeel_left_out\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'no_nan_df' is not defined"
     ]
    }
   ],
   "source": [
    "no_nan_df = no_nan_df.dropna(subset=['feel_left_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "368    False\n",
       "369     True\n",
       "370    False\n",
       "371    False\n",
       "372     True\n",
       "Length: 22160, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "\n",
    "# Step 3: Data Analysis\n",
    "\n",
    "Now that we have preprocessed data, we want to analyze it. Recall that our goal is to visualize a relationship between poverty level and general health. Before we do this, we should get a better grasp of what is in our data.\n",
    "\n",
    "## Counting Values\n",
    "The first thing we will want to do is count values of poverty levels: we want to see how many levels there are, and how the data are distributed. First, run `value_counts()` on the `poverty_level` column. \n",
    "\n",
    "üìù **Poll PyFun 6-1**: Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) for `value_counts()`. What parameter can you use to normalize the output?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a Function\n",
    "\n",
    "It turns out that poverty is expressed \"as Times of 100% Federal Poverty Line (FPL)\".\n",
    "For instance, `\"100-199%\" FPL\"` means that the row's income was 1-1.99 times the FPL.\n",
    "One approach to this statistic could be to see if we can find differences in general health for people **below and above the poverty line**. \n",
    "\n",
    "To do this, we can create a function that takes in values of the `poverty_level` column and outputs whether that value is above or below the poverty line.\n",
    "\n",
    "1. Create a new function called `assign_level`. It takes one parameter, which we'll call `i`.\n",
    "2. If `i` is `\"0-99% FPL\"`, return 0. In all other cases, return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Function\n",
    "\n",
    "Recall that we can use the `apply()` method in Pandas to apply our new function to the `poverty_level` column of our DataFrame. We also want to save the output of this `apply()` method to a new column in our DataFrame. \n",
    "\n",
    "1. Use the `apply()` method on the `poverty_level` column. Pass your `assign_level` function as the argument.\n",
    "3. Save the result of this operation in a new column in your `df`, called `above_poverty_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting a DataFrame\n",
    "\n",
    "In order to create two bar plots of general health ‚Äì for people above and below the poverty line ‚Äì we can create two DataFrames for just these groups. We can then plot the values in these DataFrames \"on top of\" one another in a barplot.\n",
    "\n",
    "Recall that we can subset DataFrames with Boolean masks. For instance, say we have a DataFrame `counts` with a column `A`. If we want to create a new DataFrame called `above_800`, which only contains the values over 800 in column `A` of `counts`, we would write:\n",
    "\n",
    "```\n",
    "above_800 = counts[counts['A'] > 800]\n",
    "```\n",
    "\n",
    "Let's perform the same operation on our data.\n",
    "\n",
    "1. Create a new DataFrame, `df_below`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 0.\n",
    "2. Create a new DataFrame, `df_above`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_below = ...\n",
    "df_above = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Visualization\n",
    "\n",
    "Finally, let's create our bar plots. We will create 2 plots in 1 cell, which will be plotted on top of one another. \n",
    "\n",
    "Fill in the blanks below, following the steps. \n",
    "\n",
    "1. Run a **normalized** `value_counts()` on the `general_health` column of `df_above` and `df_below`.\n",
    "2. We are running `plot()` on the output of the resulting DataFrame. Enter the values for two arguments: `kind` must be set to `bar`, and `alpha` must be set to `.5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_above[...].value_counts(...).plot(kind=..., alpha=...);\n",
    "df_below[...].value_counts(...).plot(kind=..., alpha=...,color='maroon');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Poll PyFun 6-2**:What is the `alpha` parameter doing? Read through the [documentation](https://pandas.pydata.org/docs/user_guide/visualization.html) to find out.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Well Done!\n",
    "\n",
    "Today's project took us through a data science workflow in Python:\n",
    "\n",
    "- Importing multiple .csv files\n",
    "- Exploratory Data Analysis\n",
    "- Basic visualization\n",
    "\n",
    "### üí° Tip: More Workshops!\n",
    "\n",
    "D-Lab teaches workshops that allow you to practice more with DataFrames and visualization.\n",
    "\n",
    "- To learn more about Pandas and data wrangling, check out D-Lab's [Python Data Wrangling workshop](https://github.com/dlab-berkeley/Python-Data-Wrangling).\n",
    "- To learn more about data visualization, check out D-Lab's [Python Data Visualization workshop](https://github.com/dlab-berkeley/Python-Data-Visualization).\n",
    "- To learn more about text analysis, check out D-Lab's [Python Text Analysis workshop](https://github.com/dlab-berkeley/Python-Text-Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* File structures can be navigated using absolute and relative file paths.\n",
    "* The `.dropna()` method in Pandas removes missing values from a `DataFrame` or `Series`.\n",
    "* Custom Functions can be applied to the axis of a DataFrame using `apply()`.\n",
    "* Subsetting DataFrames based on some condition can help with creating comparative visualizations.    \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
