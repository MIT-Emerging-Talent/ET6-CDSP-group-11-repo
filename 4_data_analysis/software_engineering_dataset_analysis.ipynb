{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3281f3ce",
   "metadata": {},
   "source": [
    "# Data Analysis: Software Engineer Earnings\n",
    "\n",
    "This notebook performs inferential and statistical analysis to address the research question:\n",
    "\n",
    "**\"What demographic factors influence median weekly earnings for software engineers in the U.S. tech industry?\"**\n",
    "\n",
    "We build on our data exploration by using statistical modeling to assess how gender, education, race, and age contribute to earnings differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53813e3",
   "metadata": {},
   "source": [
    "# Analysis Methodology\n",
    "\n",
    "Our analytical approach follows these key steps:\n",
    "\n",
    "1. **Statistical Tests Selection**\n",
    "   - Two-sample t-test for gender wage differences\n",
    "   - One-way ANOVA for education and racial differences\n",
    "   - Multiple regression for combined effects\n",
    "\n",
    "2. **Assumptions Checking**\n",
    "   - We'll verify the assumptions underlying our statistical tests\n",
    "   - Test for normality, homoscedasticity, and independence\n",
    "\n",
    "3. **Effect Size Calculation**\n",
    "   - Beyond statistical significance, we'll measure practical significance\n",
    "   - Cohen's d for t-tests\n",
    "   - Eta-squared for ANOVA\n",
    "   - Standardized coefficients for regression\n",
    "\n",
    "4. **Model Validation**\n",
    "   - Cross-validation to assess model stability\n",
    "   - Residual analysis\n",
    "   - Multicollinearity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2023a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries and dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/Users/user/Documents/mit_stuff/CDSP_GROUP_11/ET6-CDSP-group-11-repo/1_datasets/software_engineers_employment_dataset_cleaned.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc82733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 20.08, p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Gender based earnings (t-test)\n",
    "male = df[df[\"SEX\"] == 1][\"weekly_earnings\"]\n",
    "female = df[df[\"SEX\"] == 2][\"weekly_earnings\"]\n",
    "\n",
    "t_stat, p_val = ttest_ind(male, female, equal_var=False)\n",
    "print(f\"T-statistic: {t_stat:.2f}, p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a17808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assumptions for t-test\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def check_normality(data, group_name):\n",
    "    # Shapiro-Wilk test\n",
    "    stat, p_val = stats.shapiro(data)\n",
    "    print(f\"\\nNormality Test for {group_name}:\")\n",
    "    print(f\"Shapiro-Wilk test: statistic={stat:.4f}, p-value={p_val:.4f}\")\n",
    "    \n",
    "    # Q-Q plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"Q-Q Plot for {group_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# Check normality for both groups\n",
    "check_normality(male, \"Male Earnings\")\n",
    "check_normality(female, \"Female Earnings\")\n",
    "\n",
    "# Levene's test for homogeneity of variances\n",
    "levene_stat, levene_p = stats.levene(male, female)\n",
    "print(\"\\nHomogeneity of Variances:\")\n",
    "print(f\"Levene's test: statistic={levene_stat:.4f}, p-value={levene_p:.4f}\")\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "d = (male.mean() - female.mean()) / np.sqrt(((len(male) - 1) * male.var() + \n",
    "                                           (len(female) - 1) * female.var()) / \n",
    "                                          (len(male) + len(female) - 2))\n",
    "print(f\"\\nEffect Size:\")\n",
    "print(f\"Cohen's d: {d:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b48813",
   "metadata": {},
   "source": [
    "There is a statistically significant difference in weekly earnings between male and female software engineers.\n",
    "\n",
    "The low p-value means the difference in means is not due to chance, and you can reject the null hypothesis (which assumes no gender-based difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52ee3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 100.50, p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Education Level Earnings (ANOVA)\n",
    "edu_groups = [group[\"weekly_earnings\"].values for _, group in df.groupby(\"EDUC\")]\n",
    "f_stat, p_val = f_oneway(*edu_groups)\n",
    "print(f\"F-statistic: {f_stat:.2f}, p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342878b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc analysis and effect size for education levels\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['weekly_earnings'],\n",
    "                         groups=df['EDUC'],\n",
    "                         alpha=0.05)\n",
    "print(\"Post-hoc Tukey HSD test for education levels:\")\n",
    "print(tukey)\n",
    "\n",
    "# Calculate effect size (Eta-squared)\n",
    "def calculate_eta_squared(groups):\n",
    "    grand_mean = np.concatenate(groups).mean()\n",
    "    n_total = sum(len(group) for group in groups)\n",
    "    \n",
    "    ss_between = sum(len(group) * (group.mean() - grand_mean)**2 for group in groups)\n",
    "    ss_total = sum((val - grand_mean)**2 for group in groups for val in group)\n",
    "    \n",
    "    eta_squared = ss_between / ss_total\n",
    "    return eta_squared\n",
    "\n",
    "eta_squared = calculate_eta_squared(edu_groups)\n",
    "print(f\"\\nEffect Size:\")\n",
    "print(f\"Eta-squared: {eta_squared:.4f}\")\n",
    "\n",
    "# Visualize mean differences with confidence intervals\n",
    "plt.figure(figsize=(12, 6))\n",
    "tukey.plot_simultaneous()\n",
    "plt.title(\"Pairwise Mean Differences in Earnings by Education Level\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e9f81",
   "metadata": {},
   "source": [
    "Education level has a statistically significant effect on weekly earnings.\n",
    "\n",
    "You can reject the null hypothesis (that all education groups have the same mean earnings).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.1107\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = df[[\"AGE\", \"SEX\", \"EDUC\", \"RACE\"]]\n",
    "y = df[\"weekly_earnings\"]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_features = [\"SEX\", \"EDUC\", \"RACE\"]\n",
    "numeric_features = [\"AGE\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", LinearRegression())]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab370c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation and diagnostics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "print(\"Cross-validation R² scores:\")\n",
    "print(f\"Mean R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Fit the model on all data for diagnostics\n",
    "pipeline.fit(X, y)\n",
    "y_pred_all = pipeline.predict(X)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y - y_pred_all\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_pred_all, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "# QQ plot of residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "feature_names = (\n",
    "    [f\"SEX_{i}\" for i in range(1, len(df['SEX'].unique()))] +\n",
    "    [f\"EDUC_{i}\" for i in range(1, len(df['EDUC'].unique()))] +\n",
    "    [f\"RACE_{i}\" for i in range(1, len(df['RACE'].unique()))] +\n",
    "    ['AGE']\n",
    ")\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create DataFrame of features and their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "coef_df = coef_df.sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most influential features:\")\n",
    "print(coef_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ab754",
   "metadata": {},
   "source": [
    "The R2 is is relatively low, meaning:\n",
    "\n",
    "These demographic features alone do not explain most of the variability in wages.\n",
    "\n",
    "There are likely other important variables (e.g., experience, job title, company, region, skills) not included here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ced5ea",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis Results\n",
    "\n",
    "## Statistical Validity\n",
    "\n",
    "1. **Assumptions Testing**\n",
    "   - Normality assumptions were tested using Shapiro-Wilk test and Q-Q plots\n",
    "   - Homogeneity of variances verified with Levene's test\n",
    "   - Residual analysis shows the appropriateness of linear modeling\n",
    "\n",
    "2. **Effect Sizes**\n",
    "   - Cohen's d for gender differences indicates practical significance\n",
    "   - Eta-squared for education effects shows the proportion of variance explained\n",
    "   - Standardized coefficients reveal relative importance of predictors\n",
    "\n",
    "3. **Model Robustness**\n",
    "   - Cross-validation demonstrates stability of results\n",
    "   - Residual analysis confirms model assumptions\n",
    "   - Feature importance analysis reveals key predictors\n",
    "\n",
    "## Limitations and Considerations\n",
    "\n",
    "1. **Data Constraints**\n",
    "   - Missing variables (experience, specific roles, location)\n",
    "   - Potential sampling biases\n",
    "   - Cross-sectional nature of data\n",
    "\n",
    "2. **Statistical Considerations**\n",
    "   - Assumptions violations where present\n",
    "   - Multiple testing implications\n",
    "   - Model specification uncertainty\n",
    "\n",
    "3. **Practical Implications**\n",
    "   - Effect sizes in context of industry standards\n",
    "   - Policy relevance of findings\n",
    "   - Areas needing further investigation\n",
    "\n",
    "## Recommendations for Future Analysis\n",
    "\n",
    "1. **Additional Data Collection**\n",
    "   - Job-specific variables\n",
    "   - Company characteristics\n",
    "   - Geographic information\n",
    "   - Longitudinal tracking\n",
    "\n",
    "2. **Methodological Improvements**\n",
    "   - Non-linear relationships\n",
    "   - Interaction effects\n",
    "   - Hierarchical modeling\n",
    "   - Causal inference approaches\n",
    "\n",
    "3. **Validation Strategies**\n",
    "   - External validation datasets\n",
    "   - Qualitative validation\n",
    "   - Industry expert review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
